{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMR+2vZxwKmZUcMmjcingmk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["https://pytorch.org/tutorials/index.html\n","\n","https://yutaroogawa.github.io/pytorch_tutorials_jp/\n","\n","\n","ここの内容を噛み砕いたものが多いのでわからない場合はここを見てください"],"metadata":{"id":"bDa_xPvPRu5q"}},{"cell_type":"markdown","source":["machine learning\n","====================\n","\n","ここに置いてあるnotebookを全部見た後にもっかいみたら何が書いてあるかかなりわかるようになると思う．\n","\n","雰囲気をざっくり書いておく．"],"metadata":{"id":"wJBQuamcsIxI"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"6H9A2NuarlW8"},"outputs":[],"source":["from PIL import Image\n","import os\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from typing import Any, Callable, Optional, Tuple\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.utils as utils\n","import torchvision\n","import torchvision.utils as vutils\n","import torchvision.datasets as dset\n","import torchvision.transforms as transforms\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","\n","\n","import time\n","from torch.optim.optimizer import Optimizer\n","from typing import List\n","from torch import Tensor\n","import numpy"]},{"cell_type":"markdown","source":["Cutout\n","===============\n","\n","データ拡張の一つ\n","汎化性能を大きく向上させてくれる"],"metadata":{"id":"IfbDmU6tv0O2"}},{"cell_type":"code","source":["class Cutout:\n","    def __init__(self, size=16, p=0.5):\n","        self.size = size\n","        self.half_size = size // 2\n","        self.p = p\n","\n","    def __call__(self, image):\n","        if torch.rand([1]).item() > self.p:\n","            return image\n","\n","        left = torch.randint(-self.half_size, image.size(1) - self.half_size, [1]).item()\n","        top = torch.randint(-self.half_size, image.size(2) - self.half_size, [1]).item()\n","        right = min(image.size(1), left + self.size)\n","        bottom = min(image.size(2), top + self.size)\n","\n","        image[:, max(0, left): right, max(0, top): bottom] = 0\n","        return image"],"metadata":{"id":"kFTqIwPosgJa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["データセット\n","=============\n","\n","今回の学習にはCifar10を使ってる\n"],"metadata":{"id":"gL5Js76Vv-W9"}},{"cell_type":"code","source":["class Cifar10:\n","    def __init__(self, batch_size, threads):\n","        mean, std = self._get_statistics()\n","\n","        train_transform = transforms.Compose([\n","            torchvision.transforms.RandomCrop(size=(32, 32), padding=4),\n","            torchvision.transforms.RandomHorizontalFlip(),\n","            transforms.ToTensor(),\n","            transforms.Normalize(mean, std),\n","            Cutout()\n","        ])\n","\n","        test_transform = transforms.Compose([\n","            transforms.ToTensor(),\n","            transforms.Normalize(mean, std)\n","        ])\n","\n","        train_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n","        test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n","\n","        self.train = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=threads)\n","        self.test = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=threads)\n","\n","        self.classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n","\n","    def _get_statistics(self):\n","        train_set = torchvision.datasets.CIFAR10(root='./cifar', train=True, download=True, transform=transforms.ToTensor())\n","\n","        data = torch.cat([d[0] for d in DataLoader(train_set)])\n","        return data.mean(dim=[0, 2, 3]), data.std(dim=[0, 2, 3])"],"metadata":{"id":"fFZ5bZAmsh9F"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["ハイパーパラメータ\n","================\n","\n","自分で調整する量\n","\n","今回は学習の負担を軽くするためにepoch数を小さくしてる\n","\n","普通ならepochs = 200くらいになる．"],"metadata":{"id":"lmFDKJgZwGoI"}},{"cell_type":"code","source":["###############\n","# 入力パラメータ\n","###############\n","#バッチサイズ\n","batch_size = 128\n","#エポック数\n","epochs = 10\n","#GPUID\n","ngpu = 1\n","#学習率\n","lr = 0.1\n","#スレッド数\n","threads = 2\n","\n","#device = torch.device(\"cuda:6\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n","use_cuda = torch.cuda.is_available()\n","if use_cuda:\n","    torch.cuda.empty_cache()\n","    torch.cuda.set_device(0)"],"metadata":{"id":"x-kEkWoRsvMF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset = Cifar10(batch_size,threads)\n","train_data = dataset.train\n","test_data = dataset.test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-8TsQB-Ssy2d","executionInfo":{"status":"ok","timestamp":1666935134146,"user_tz":-540,"elapsed":17323,"user":{"displayName":"佐々木小次郎","userId":"09458700915206684906"}},"outputId":"93d5ebb1-8f97-4fb0-8fa5-9e8c0944bab7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","Files already downloaded and verified\n"]}]},{"cell_type":"markdown","source":["モデル\n","============\n","\n","ネットワークを定義している\n","\n","今回は学習の計算の負担を軽くするために小さなモデルを使ってる"],"metadata":{"id":"Nllf89P8xXRm"}},{"cell_type":"code","source":["class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 6, 5)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.conv2 = nn.Conv2d(6, 16, 5)\n","        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n","        self.fc2 = nn.Linear(120, 84)\n","        self.fc3 = nn.Linear(84, 10)\n","\n","    def forward(self, x):\n","        x = self.pool(F.relu(self.conv1(x)))\n","        x = self.pool(F.relu(self.conv2(x)))\n","        x = x.view(-1, 16 * 5 * 5)\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x"],"metadata":{"id":"OnJZlNhUtB9w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model=Net().cuda()"],"metadata":{"id":"jPaqoBXIDGVy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["最適化手法\n","============\n","\n","最適化手法の定義をしている\n","\n","今回使っているのはSGDたくさんのオプションがあるので気になる人はググって使うといい\n","https://pytorch.org/docs/stable/generated/torch.optim.SGD.html"],"metadata":{"id":"UV8Jdrj0E5O2"}},{"cell_type":"code","source":["optimizer = torch.optim.SGD(model.parameters(),lr=lr)"],"metadata":{"id":"DC61mkIAC9an"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["損失関数\n","-------------------------\n","損失関数の定義をしている\n","\n","criterionとすることが多い．\n","\n","これもたくさんの関数があるので気になる人はググると良い\n","\n","今回はクロスエントロピー誤差を使う．"],"metadata":{"id":"MKU77OP-E4-v"}},{"cell_type":"code","source":["criterion = nn.CrossEntropyLoss()"],"metadata":{"id":"7LWXuq_SFqxi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["学習率減衰\n","==================\n","\n","学習を進めていく過程で常に同じ学習率だと停滞が起こる．\n","\n","そこで一定のエポック数で学習率を小さくしてあげる必要がありここで定義した関数で学習率を操作する．\n","\n","今回は総エポック数が小さいので動作しない(epochが20ごとに0.5倍)が後学のために載せる．"],"metadata":{"id":"SS4J1P3IxkTR"}},{"cell_type":"code","source":["scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)"],"metadata":{"id":"n6pAztjntn0W"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["訓練\n","==================\n","\n","訓練を行う関数\n","\n","基本的な流れとしては\n","\n","1「入力」を「モデル」に入れて「ラベル」との「損失」を出す\n","\n","2「損失」の勾配計算を行い，パラメータ更新を行う\n","\n","3「学習率減衰」と「精度」や「損失値」の計算を行う\n","\n","といった流れ"],"metadata":{"id":"SSe5MA1OFydC"}},{"cell_type":"code","source":["def train(epoch):\n","    model.train()\n","    train_loss = 0.0\n","    correct = 0.0\n","\n","    for inputs, target in dataset.train:\n","        optimizer.zero_grad()\n","        input_size = inputs.size()[0]\n","        inputs, target = inputs.cuda(), target.cuda()\n","        output = model(inputs)\n","        loss = loss_func(output, target)\n","        loss.backward()\n","        optimizer.step()\n","        if epoch >= args.start_averaged:\n","            averaged_model.update_parameters(model)\n","        with torch.no_grad():\n","            train_loss += loss.data * input_size/total_train\n","            _, pred = torch.max(output, 1)\n","            correct += pred.eq(target).sum()/total_train\n","\n","\n","    return train_loss, 100*correct"],"metadata":{"id":"kHaNGaN1tUoR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["予測\n","==================\n","\n","予測を行う関数\n","\n","基本的な流れとしては\n","\n","1「入力」を「モデル」に入れて「ラベル」との「損失」を出す\n","\n","2「精度」や「損失値」の計算を行う\n","\n","といった流れ\n","\n","訓練の時と違ってパラメータ更新を行う必要がないので勾配計算は行わない"],"metadata":{"id":"Zgrr_1kjHR7S"}},{"cell_type":"code","source":["def test(epoch):\n","    loss_epoch = 0.0\n","    acc_epoch = 0.0\n","\n","    with torch.no_grad():\n","        for inputs,labels in test_data:\n","          #1「入力」を「モデル」に入れて「ラベル」との「損失」を出す\n","          labels = labels.cuda()\n","          inputs = inputs.cuda()\n","          outputs = model(inputs)\n","          loss = criterion(outputs,labels)\n","          _,preds = torch.max(outputs,1)\n","\n","          #2「精度」や「損失値」の計算を行う\n","          loss_epoch += loss.item() * inputs.size(0)\n","          acc_epoch += torch.sum(preds == labels.detach())\n","\n","        loss_epoch = loss_epoch / len(test_data.dataset)\n","        acc_epoch = acc_epoch.double() / len(test_data.dataset)\n","        return loss_epoch,acc_epoch\n","\n","def test(epoch):\n","    model.eval()\n","    averaged_model.eval()\n","\n","    test_loss = 0.0\n","    test_correct = 0.0\n","\n","    with torch.no_grad():\n","        for inputs, target in dataset.test:\n","            input_size = inputs.size()[0]\n","            inputs, target = inputs.cuda(), target.cuda()\n","            #normal_prediction\n","            predict = model(inputs)\n","            loss = loss_func(predict, target)\n","            test_loss += loss.data * input_size / total_test\n","            _, pred = torch.max(predict.data, 1)\n","            test_correct += pred.eq(target).sum() / total_test\n","\n","    return test_loss, 100*test_correct"],"metadata":{"id":"9dNW6DQgtnOc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["メイン\n","==================\n","\n","定義してきた関数を使って学習と予測をエポック数分行う．\n"],"metadata":{"id":"U_tDnQlgH0Wb"}},{"cell_type":"code","source":["for epoch in range(epochs):\n","\n","    torch.cuda.synchronize()\n","    start = time.time()\n","    model.train()\n","\n","    train_loss,train_acc = train(epoch)\n","\n","    torch.cuda.synchronize()\n","    train_time = time.time() - start\n","\n","    print(f\"epoch:{epoch}\",\n","            f\"train_loss:{train_loss:.4f}\",\n","            f\"train_acc:{train_acc:.4f}\",\n","            f\"time:{train_time:.4f}\")\n","\n","    model.eval()\n","    test_loss,test_acc = test(epoch)\n","\n","    torch.cuda.synchronize()\n","    test_time = time.time() - start\n","\n","    print(f\"epoch:{epoch}\",\n","            f\"test_loss:{test_loss:.4f}\",\n","            f\"test_acc:{test_acc:.4f}\",\n","            f\"time:{test_time:.4f}\")\n","\n","\n","print('Finished Training')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zE3xcINGt6IZ","executionInfo":{"status":"ok","timestamp":1666935335844,"user_tz":-540,"elapsed":199658,"user":{"displayName":"佐々木小次郎","userId":"09458700915206684906"}},"outputId":"64a64051-58d0-431f-96dc-7998aa234835"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch:0 train_loss:2.2492 train_acc:0.1667 time:19.5128\n","epoch:0 test_loss:2.2320 test_acc:0.1841 time:21.8332\n","epoch:1 train_loss:2.2417 train_acc:0.1772 time:17.5058\n","epoch:1 test_loss:2.2320 test_acc:0.1841 time:19.7373\n","epoch:2 train_loss:2.2416 train_acc:0.1757 time:17.1860\n","epoch:2 test_loss:2.2320 test_acc:0.1841 time:19.5927\n","epoch:3 train_loss:2.2420 train_acc:0.1766 time:16.4482\n","epoch:3 test_loss:2.2320 test_acc:0.1841 time:18.3899\n","epoch:4 train_loss:2.2419 train_acc:0.1762 time:16.7059\n","epoch:4 test_loss:2.2320 test_acc:0.1841 time:18.6992\n","epoch:5 train_loss:2.2412 train_acc:0.1771 time:16.4898\n","epoch:5 test_loss:2.2320 test_acc:0.1841 time:18.4455\n","epoch:6 train_loss:2.2417 train_acc:0.1772 time:17.2668\n","epoch:6 test_loss:2.2320 test_acc:0.1841 time:20.1913\n","epoch:7 train_loss:2.2415 train_acc:0.1771 time:19.8106\n","epoch:7 test_loss:2.2320 test_acc:0.1841 time:22.2965\n","epoch:8 train_loss:2.2421 train_acc:0.1758 time:17.9071\n","epoch:8 test_loss:2.2320 test_acc:0.1841 time:20.4635\n","epoch:9 train_loss:2.2421 train_acc:0.1765 time:18.3786\n","epoch:9 test_loss:2.2320 test_acc:0.1841 time:20.3255\n","Finished Training\n"]}]}]}