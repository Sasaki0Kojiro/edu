{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMgR0/Gjvi2IVEnEOab2oWN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["パラメータの最適化\n","===========================\n","\n","モデルとデータを用意できたので続いてはモデルを訓練、検証することで、データに対してモデルのパラメータを最適化し、テストを行う．\n","\n","細かな説明は省くので何をしているのかいまいち思い出せない人は前のチュートリアルに戻るのもあり．"],"metadata":{"id":"Vl-aR1gZmCd-"}},{"cell_type":"markdown","source":["データセット\n","==============\n","\n","前にやったデータセットを作るコードと同じ．"],"metadata":{"id":"tWWrRpMSmmPy"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"2W50ghg9l3RW"},"outputs":[],"source":["import torch\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor, Lambda\n","\n","training_data = datasets.FashionMNIST(\n","    root=\"data\",\n","    train=True,\n","    download=True,\n","    transform=ToTensor()\n",")\n","\n","test_data = datasets.FashionMNIST(\n","    root=\"data\",\n","    train=False,\n","    download=True,\n","    transform=ToTensor()\n",")\n","\n","train_dataloader = DataLoader(training_data, batch_size=64)\n","test_dataloader = DataLoader(test_data, batch_size=64)"]},{"cell_type":"markdown","source":["ネットワーク構築\n","================\n","\n","同じ．"],"metadata":{"id":"chOWNTj0mxCh"}},{"cell_type":"code","source":["class NeuralNetwork(nn.Module):\n","    def __init__(self):\n","        super(NeuralNetwork, self).__init__()\n","        self.flatten = nn.Flatten()\n","        self.linear_relu_stack = nn.Sequential(\n","            nn.Linear(28*28, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 10),\n","            nn.ReLU()\n","        )\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        logits = self.linear_relu_stack(x)\n","        return logits\n","\n","model = NeuralNetwork()"],"metadata":{"id":"DkrwrkWVmgsq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["ハイパーパラメータ\n","==============\n","\n","機械学習を進める上でネットワークの重み(パラメータ)やバイアスを最適化することになるが，よりうまく判別を行うために使い手（ぼくら）がイジる要素をハイパーパラメータと呼ぶ．\n","\n","よく調整するハイパーパラメータは以下\n"," - **Epochs**：エポックの数．1エポックで一つのデータセットを一周した形になる．\n"," - **Batch Size**：ミニバッチサイズを構成するデータ数．大きいほど理論上分散は小さくなる\n"," - **Learning Rate**：パラメータ更新の係数．momentumが登場してから``0.1``とされることが多い．\n"],"metadata":{"id":"P4iJP7snm5t2"}},{"cell_type":"code","source":["epochs = 10\n","batch_size = 64\n","learning_rate = 0.1\n","\n","\"ここの値は一回終わった後に調整を推奨\"\n","momentum = 0.0\n","weight_decay = 0.0"],"metadata":{"id":"drNoxZqapFFD","executionInfo":{"status":"ok","timestamp":1666938195668,"user_tz":-540,"elapsed":5,"user":{"displayName":"佐々木小次郎","userId":"09458700915206684906"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["損失関数\n","================\n","\n","一般的な損失関数としては、回帰タスクでは[`nn.MSELoss`](https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html#torch.nn.MSELoss)(Mean Square Error)、分類タスクでは[`nn.NLLLoss`](https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html#torch.nn.NLLLoss)(Negative Log Likelihood) が使用されることが多い．\n","\n","[`nn.CrossEntropyLoss`](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss)は、``nn.LogSoftmax`` と ``nn.NLLLoss``を結合した損失関数．\n","\n","モデルが出力する`logit`値を`nn.CrossEntropyLoss`に与えて正規化し、予測誤差を求めることになる"],"metadata":{"id":"EZF_RlmJoNLc"}},{"cell_type":"code","source":["loss = nn.CrossEntropyLoss()"],"metadata":{"id":"j2py1-ZVoF04"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["torch.optim\n","================\n","\n","使いたい最適化アルゴリズムをここで定義できる．\n","\n","最適化アルゴリズムを自分で書いて定義する必要はない．"],"metadata":{"id":"8kipfPxiokwL"}},{"cell_type":"code","source":["optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate,momentum = momentum,weight_decay = weight_decay)"],"metadata":{"id":"lyXGSrCeoekL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["trainとtest\n","===================\n","\n","最適化を行うtrainを予測を行うtestを実装する\n"],"metadata":{"id":"k0xd0CBDpVdP"}},{"cell_type":"code","source":["def train_loop(dataloader, model, loss_fn, optimizer):\n","    size = len(dataloader.dataset)\n","    for batch, (X, y) in enumerate(dataloader):        \n","        # 予測と損失の計算\n","        pred = model(X)\n","        loss = loss_fn(pred, y)\n","        \n","        # バックプロパゲーション\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        if batch % 100 == 0:\n","            loss, current = loss.item(), batch * len(X)\n","            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n","\n","\n","def test_loop(dataloader, model, loss_fn):\n","    size = len(dataloader.dataset)\n","    test_loss, correct = 0, 0\n","\n","    with torch.no_grad():\n","        for X, y in dataloader:\n","            pred = model(X)\n","            test_loss += loss_fn(pred, y).item()\n","            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n","            \n","    test_loss /= size\n","    correct /= size\n","    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"],"metadata":{"id":"xIZ4FyQ7pDQG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["実践\n","==============\n","\n","これまで使ってきたコードを使って学習を行うことができる．\n","\n","以下のコードを使って実際に精度を確認してみよう"],"metadata":{"id":"Hts9DXh0qBT5"}},{"cell_type":"code","source":["loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n","\n","epochs = 10\n","for t in range(epochs):\n","    print(f\"Epoch {t+1}\\n-------------------------------\")\n","    train_loop(train_dataloader, model, loss_fn, optimizer)\n","    test_loop(test_dataloader, model, loss_fn)\n","print(\"Done!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lTjFh4hmp9Mf","executionInfo":{"status":"ok","timestamp":1652164486422,"user_tz":-540,"elapsed":146314,"user":{"displayName":"佐々木小次郎","userId":"09458700915206684906"}},"outputId":"05034238-7caa-4d80-bf7c-2ee2327b5583"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1\n","-------------------------------\n","loss: 2.312256  [    0/60000]\n","loss: 1.165897  [ 6400/60000]\n","loss: 0.795653  [12800/60000]\n","loss: 0.862054  [19200/60000]\n","loss: 0.721507  [25600/60000]\n","loss: 0.667579  [32000/60000]\n","loss: 0.740483  [38400/60000]\n","loss: 0.789138  [44800/60000]\n","loss: 0.758234  [51200/60000]\n","loss: 0.724965  [57600/60000]\n","Test Error: \n"," Accuracy: 77.5%, Avg loss: 0.011495 \n","\n","Epoch 2\n","-------------------------------\n","loss: 0.665897  [    0/60000]\n","loss: 0.673182  [ 6400/60000]\n","loss: 0.616533  [12800/60000]\n","loss: 0.622670  [19200/60000]\n","loss: 0.585112  [25600/60000]\n","loss: 0.584928  [32000/60000]\n","loss: 0.615958  [38400/60000]\n","loss: 0.727573  [44800/60000]\n","loss: 0.674120  [51200/60000]\n","loss: 0.668467  [57600/60000]\n","Test Error: \n"," Accuracy: 78.9%, Avg loss: 0.010828 \n","\n","Epoch 3\n","-------------------------------\n","loss: 0.610003  [    0/60000]\n","loss: 0.611965  [ 6400/60000]\n","loss: 0.556257  [12800/60000]\n","loss: 0.545826  [19200/60000]\n","loss: 0.530171  [25600/60000]\n","loss: 0.554525  [32000/60000]\n","loss: 0.567494  [38400/60000]\n","loss: 0.676763  [44800/60000]\n","loss: 0.529643  [51200/60000]\n","loss: 0.480125  [57600/60000]\n","Test Error: \n"," Accuracy: 82.0%, Avg loss: 0.007784 \n","\n","Epoch 4\n","-------------------------------\n","loss: 0.335314  [    0/60000]\n","loss: 0.365681  [ 6400/60000]\n","loss: 0.296792  [12800/60000]\n","loss: 0.344377  [19200/60000]\n","loss: 0.348255  [25600/60000]\n","loss: 0.400147  [32000/60000]\n","loss: 0.363076  [38400/60000]\n","loss: 0.467284  [44800/60000]\n","loss: 0.448044  [51200/60000]\n","loss: 0.428747  [57600/60000]\n","Test Error: \n"," Accuracy: 84.3%, Avg loss: 0.006729 \n","\n","Epoch 5\n","-------------------------------\n","loss: 0.263883  [    0/60000]\n","loss: 0.313281  [ 6400/60000]\n","loss: 0.254335  [12800/60000]\n","loss: 0.296281  [19200/60000]\n","loss: 0.314548  [25600/60000]\n","loss: 0.379511  [32000/60000]\n","loss: 0.329388  [38400/60000]\n","loss: 0.415144  [44800/60000]\n","loss: 0.400937  [51200/60000]\n","loss: 0.408558  [57600/60000]\n","Test Error: \n"," Accuracy: 85.3%, Avg loss: 0.006342 \n","\n","Epoch 6\n","-------------------------------\n","loss: 0.235260  [    0/60000]\n","loss: 0.294587  [ 6400/60000]\n","loss: 0.228716  [12800/60000]\n","loss: 0.272919  [19200/60000]\n","loss: 0.304897  [25600/60000]\n","loss: 0.374537  [32000/60000]\n","loss: 0.309589  [38400/60000]\n","loss: 0.382069  [44800/60000]\n","loss: 0.374567  [51200/60000]\n","loss: 0.384939  [57600/60000]\n","Test Error: \n"," Accuracy: 86.1%, Avg loss: 0.006013 \n","\n","Epoch 7\n","-------------------------------\n","loss: 0.211928  [    0/60000]\n","loss: 0.285788  [ 6400/60000]\n","loss: 0.214228  [12800/60000]\n","loss: 0.247664  [19200/60000]\n","loss: 0.301945  [25600/60000]\n","loss: 0.362229  [32000/60000]\n","loss: 0.279063  [38400/60000]\n","loss: 0.355164  [44800/60000]\n","loss: 0.341156  [51200/60000]\n","loss: 0.379098  [57600/60000]\n","Test Error: \n"," Accuracy: 86.3%, Avg loss: 0.005880 \n","\n","Epoch 8\n","-------------------------------\n","loss: 0.195849  [    0/60000]\n","loss: 0.280057  [ 6400/60000]\n","loss: 0.193942  [12800/60000]\n","loss: 0.232474  [19200/60000]\n","loss: 0.285591  [25600/60000]\n","loss: 0.353023  [32000/60000]\n","loss: 0.270129  [38400/60000]\n","loss: 0.322622  [44800/60000]\n","loss: 0.331431  [51200/60000]\n","loss: 0.363081  [57600/60000]\n","Test Error: \n"," Accuracy: 86.8%, Avg loss: 0.005677 \n","\n","Epoch 9\n","-------------------------------\n","loss: 0.183456  [    0/60000]\n","loss: 0.262472  [ 6400/60000]\n","loss: 0.177104  [12800/60000]\n","loss: 0.212457  [19200/60000]\n","loss: 0.297705  [25600/60000]\n","loss: 0.331262  [32000/60000]\n","loss: 0.249310  [38400/60000]\n","loss: 0.306213  [44800/60000]\n","loss: 0.318112  [51200/60000]\n","loss: 0.357687  [57600/60000]\n","Test Error: \n"," Accuracy: 86.9%, Avg loss: 0.005616 \n","\n","Epoch 10\n","-------------------------------\n","loss: 0.176122  [    0/60000]\n","loss: 0.258207  [ 6400/60000]\n","loss: 0.165979  [12800/60000]\n","loss: 0.203172  [19200/60000]\n","loss: 0.290217  [25600/60000]\n","loss: 0.313931  [32000/60000]\n","loss: 0.236114  [38400/60000]\n","loss: 0.297907  [44800/60000]\n","loss: 0.306301  [51200/60000]\n","loss: 0.343424  [57600/60000]\n","Test Error: \n"," Accuracy: 87.4%, Avg loss: 0.005346 \n","\n","Done!\n"]}]},{"cell_type":"markdown","source":["ハイパーパラメータを自分でいじって精度を上げてみるのもあり．\n","\n","``momentum``や``weight_decay``は今は0で定義しているのでうまいこと変えてみよう！"],"metadata":{"id":"x96XraAbqaYS"}}]}